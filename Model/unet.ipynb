{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517acbfb-5bce-4524-ac62-1d577e88ebb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d9b95b-18bd-42a9-9ad5-1504275d763c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creamos la clase que conforma el bloque convolucional del modelo\n",
    "\n",
    "class BlockConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(BlockConv, self).__init__()\n",
    "        \n",
    "        # Bloque convolucional\n",
    "        self.blockConv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01,inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.blockConv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5526f9-6258-48cc-a401-f136dbff65fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definimos la clase con la que se va a abordar el downsamplig\n",
    "\n",
    "class DownsamplingBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownsamplingBlock, self).__init__()\n",
    "        \n",
    "        # Bloque downsampling\n",
    "        self.blockConv = BlockConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, return_indices=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = self.blockConv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        \n",
    "        return (down_out, skip_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec0c5df-0c0d-4197-a5e9-3dc1a7d67134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definimos la clase con la que se aborda el upsampling\n",
    "\n",
    "class UpsamplingBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UpsamplingBlock, self).__init__()\n",
    "        \n",
    "        # Bloque upsampling\n",
    "        self.upsamplingBlock = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)\n",
    "        self.double_conv = BlockConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, down_input, skip_input):\n",
    "        \n",
    "        x = self.upsamplingBlock(down_input)\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08563dc0-5086-49ac-b44c-672d10124c7b",
   "metadata": {},
   "source": [
    "## Clase UNET\n",
    "\n",
    "##### Implementa la arquitectura del modelo UNET que vamos a utilizar para la realización de este Trabajo Fin de Grado\n",
    "\n",
    "##### La clase tiene un parámetro:\n",
    "##### - \"out_labels\": se especifíca el número de clases de salida para la tarea de segmentación. En nuestro caso el conjunto de datos esta preparado para que el modelo diferencie 5 clases diferentes. Por lo que el modelo generará 5 mapas de características diferentes, uno para cada clase.\n",
    "\n",
    "##### Como vemos la arquitectura de nuestro modelo consta de varias partes:\n",
    "\n",
    "##### - Downsampling: capas de convolución en las que se obtienen mapas de características que extraen patrones de la imagen original, estos son de menor dimensiones que la imagen original. Hay 4 capas de estas: down_1, down_2, down_3 y down_4.\n",
    "\n",
    "##### - Cuello de botella: esta es la capa denominada \"neck_conv\", y sirve de unión entre la fase de extracción y la de expansión.\n",
    "\n",
    "##### - Upsampling: capas de reconstrucción de la imagen original, y en cada capa de \"UpsamplingBlock\" se incrementa la resolución de la imagen. Hay 4 capas de estas: up_1, up_2, up_3 y up_4.\n",
    "\n",
    "##### - Convolución final: denominada \"last_conv\", es la última capa, esta reduce el número de canales a tantos como clases finales deseemos. Se consigue con un kernel de tamaño 1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b204a6-a03b-41de-9ce8-ab26e44354b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_classes):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Downsampling\n",
    "        # 3 canales de informacion --> imagenes RGB\n",
    "        self.down_1 = DownsamplingBlock(3, 64)\n",
    "        self.down_2 = DownsamplingBlock(64, 128)\n",
    "        self.down_3 = DownsamplingBlock(128, 256)\n",
    "        self.down_4 = DownsamplingBlock(256, 512)\n",
    "        \n",
    "        # Cuello de botella\n",
    "        self.neck_conv = BlockConv(512, 1024)\n",
    "        \n",
    "        # Upsampling\n",
    "        self.up_4 = UpsamplingBlock(512 + 1024, 512)\n",
    "        self.up_3 = UpsamplingBlock(256 + 512, 256)\n",
    "        self.up_2 = UpsamplingBlock(128 + 256, 128)\n",
    "        self.up_1 = UpsamplingBlock(64 + 128, 64)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Final Convolution\n",
    "        # Genera tantos planos como clases tenemos que identificar\n",
    "        self.last_conv = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "\n",
    "    # La función forward describe el flujo de los datos a través de la red\n",
    "    # Capas de downsampling --> CUello de botella --> Capas de upsampling --> Salida final\n",
    "    def forward(self, x):\n",
    "        x, skip1_out = self.down_1(x)\n",
    "        x, skip2_out = self.down_2(x)\n",
    "        x, skip3_out = self.down_3(x)\n",
    "        x, skip4_out = self.down_4(x)\n",
    "        \n",
    "        x = self.neck_conv(x)\n",
    "        \n",
    "        x = self.up_4(x, skip4_out)\n",
    "        x = self.up_3(x, skip3_out)\n",
    "        x = self.up_2(x, skip2_out)\n",
    "        x = self.up_1(x, skip1_out)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.last_conv(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc66805-c3d1-471b-9de3-1bd7feb13679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para la inicialización de pesos del modelo\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "        \n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f23b1-5ee9-41d9-ac3c-10374d10da20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
